{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd01baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "useful links:\n",
    "\n",
    "- Data Preparation for Variable Length Input Sequences, URL: https://machinelearningmastery.com/data-preparation-variable-length-input-sequences-sequence-prediction/\n",
    "- Masking and padding with Keras, URL: https://www.tensorflow.org/guide/keras/masking_and_padding\n",
    "- Step-by-step understanding LSTM Autoencoder layers, URL: https://towardsdatascience.com/step-by-step-understanding-lstm-autoencoder-layers-ffab055b6352XX, \n",
    "- Understanding input_shape parameter in LSTM with Keras, URL: https://stats.stackexchange.com/questions/274478/understanding-input-shape-parameter-in-lstm-with-keras\n",
    "- tf.convert_to_tensor, URL: https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor\n",
    "- ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type int) in Python, URL: https://datascience.stackexchange.com/questions/82440/valueerror-failed-to-convert-a-numpy-array-to-a-tensor-unsupported-object-type\n",
    "- How to Identify and Diagnose GAN Failure Modes, URL: https://machinelearningmastery.com/practical-guide-to-gan-failure-modes/\n",
    "- How to Develop a GAN for Generating MNIST Handwritten Digits\n",
    ", URL: https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/\n",
    "- How to Visualize a Deep Learning Neural Network Model in Keras\n",
    ", URL: https://machinelearningmastery.com/visualize-deep-learning-neural-network-model-keras/\n",
    "- How to Implement GAN Hacks in Keras to Train Stable Models\n",
    ", URL: https://machinelearningmastery.com/how-to-code-generative-adversarial-network-hacks/\n",
    "- aaaaaaaaa, URL: xxxxxx"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* Copyright 2020, Maestria de Humanidades Digitales,\n",
    "* Universidad de Los Andes\n",
    "*\n",
    "* Developed for the Msc graduation project in Digital Humanities\n",
    "*\n",
    "* This program is free software: you can redistribute it and/or modify\n",
    "* it under the terms of the GNU General Public License as published by\n",
    "* the Free Software Foundation, either version 3 of the License, or\n",
    "* (at your option) any later version.\n",
    "*\n",
    "* This program is distributed in the hope that it will be useful,\n",
    "* but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "* GNU General Public License for more details.\n",
    "*\n",
    "* You should have received a copy of the GNU General Public License\n",
    "* along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "\n",
    "# ===============================\n",
    "# native python libraries\n",
    "# ===============================\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import csv\n",
    "import cv2\n",
    "import datetime\n",
    "import copy\n",
    "import gc\n",
    "from statistics import mean\n",
    "from collections import OrderedDict\n",
    "from collections import Counter\n",
    "from collections import deque\n",
    "\n",
    "# ===============================\n",
    "# extension python libraries\n",
    "# ===============================\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# natural language processing packages\n",
    "import gensim\n",
    "from gensim import models\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# downloading nlkt data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# sample handling sklearn package\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "\n",
    "# # Keras + Tensorflow ML libraries\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Masking\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.optimizers import SGD # OJO!\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam # OJO!\n",
    "from tensorflow.keras.optimizers import Adadelta # OJO!\n",
    "from tensorflow.keras.optimizers import Adagrad # OJO!\n",
    "\n",
    "# https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
    "# example of random rotation image augmentation\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ===============================\n",
    "# developed python libraries\n",
    "# ==============================="
   ]
  },
  {
   "source": [
    "# FUNCTION DEFINITION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A UDF to convert input data into 3-D\n",
    "array as required for LSTM network.\n",
    "\n",
    "taken from https://towardsdatascience.com/step-by-step-understanding-lstm-autoencoder-layers-ffab055b6352\n",
    "'''\n",
    "def temporalize(data, lookback):\n",
    "    output_X = list()\n",
    "    for i in range(len(X)-lookback-1):\n",
    "        temp = list()\n",
    "        for j in range(1,lookback+1):\n",
    "            # Gather past records upto the lookback period\n",
    "            temp.append(data[[(i+j+1)], :])\n",
    "        temp = np.array(temp, dtype=\"object\")\n",
    "        output_X.append(temp)\n",
    "    output_X = np.array(output_X, dtype=\"object\")\n",
    "    return output_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(img_fpn):\n",
    "    ans = cv2.imread(img_fpn, cv2.IMREAD_UNCHANGED)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctr_std_img(img, minv, maxv):\n",
    "    rangev = maxv - minv\n",
    "    rangev = float(rangev/2)\n",
    "    ans = (img.astype(\"float32\")-rangev)/rangev\n",
    "    # ans = pd.Series(ans)\n",
    "    # respuesta de la funcion\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_img(img, minv, maxv):\n",
    "    rangev = maxv - minv\n",
    "    ans = img.astype(\"float32\")/float(rangev)\n",
    "    # ans = pd.Series(ans)\n",
    "    # respuesta de la funcion\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_img(img, h, w, img_type):\n",
    "    #  in case when you have odd number\n",
    "    ans = None\n",
    "    top_pad = np.floor((h - img.shape[0]) / 2).astype(np.uint8) # floor\n",
    "    bottom_pad = np.ceil((h - img.shape[0]) / 2).astype(np.uint8)\n",
    "    right_pad = np.ceil((w - img.shape[1]) / 2).astype(np.uint8)\n",
    "    left_pad = np.floor((w - img.shape[1]) / 2).astype(np.uint8) # floor\n",
    "    # print((top_pad, bottom_pad), (left_pad, right_pad))\n",
    "    if img_type == \"rgb\":\n",
    "        ans = np.copy(np.pad(img, ((top_pad, bottom_pad), (left_pad, right_pad), (0, 0)), mode=\"constant\", constant_values=0.0))   \n",
    "    if img_type == \"bw\":\n",
    "        ans = np.copy(np.pad(img, ((int(top_pad), int(bottom_pad)), (int(left_pad), int(right_pad))), mode=\"constant\", constant_values=0))\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to padd the images in the dataset, needs the shape, the type of image and the src + tgt columns of the frame to work with\n",
    "def padding_images(src_df, src_col, tgt_col, max_shape, img_type):\n",
    "    # ans = src_df\n",
    "    src_images = src_df[src_col]\n",
    "    tgt_images = list()\n",
    "    max_x, max_y = max_shape[0], max_shape[1]\n",
    "\n",
    "    for timg in src_images:        \n",
    "        pimg = pad_img(timg, max_y, max_x, img_type)\n",
    "        tgt_images.append(pimg)\n",
    "\n",
    "    src_df[tgt_col] = tgt_images\n",
    "    return src_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the images in in memory\n",
    "def get_images(rootf, src_df, src_col, tgt_col):\n",
    "    ans = src_df\n",
    "    src_files = list(ans[src_col])\n",
    "    tgt_files = list()\n",
    "\n",
    "    # ansdict = {}\n",
    "    for tfile in src_files:\n",
    "        tfpn = os.path.join(rootf, tfile)\n",
    "        timg = read_img(tfpn)\n",
    "        tgt_files.append(timg)\n",
    "\n",
    "    ans[tgt_col] = tgt_files\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to augment the images in the dataset and virtualy exapnd the training examples\n",
    "def augment_images(src_df, src_col, tgt_col, syth_num):\n",
    "\n",
    "    cols = [list(src_df.columns.values)]\n",
    "    # print(cols)\n",
    "    ans = pd.DataFrame()\n",
    "    other_cols = list(src_df.columns.values)\n",
    "    other_cols.remove(tgt_col)\n",
    "    other_cols.remove(src_col)\n",
    "    # print(other_cols)\n",
    "\n",
    "    for index, row in src_df.iterrows():\n",
    "        t_txt = row[src_col]\n",
    "        t_img = row[tgt_col]\n",
    "        t_tags = row[other_cols]\n",
    "\n",
    "        gen_rows = list()\n",
    "        for i in range(syth_num):\n",
    "\n",
    "            gen_tags = copy.deepcopy(t_tags)\n",
    "            gen_img = syth_img(t_img)\n",
    "            gen_txt = syth_text(t_txt)\n",
    "            # print(type(gen_tags), type(gen_img)) \n",
    "            gen_tags[tgt_col] = gen_img\n",
    "            gen_tags[src_col] = gen_txt\n",
    "            gen_rows.append(gen_tags)\n",
    "            # print(gen_tags) # , type(gen_img)) \n",
    "            # [other_cols], row[tgt_col])\n",
    "        \n",
    "        ans = ans.append(gen_rows, ignore_index=True)\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function than rotates the original image to create a new example\n",
    "def syth_img(data):\n",
    "\n",
    "    samples = expand_dims(data, 0)\n",
    "    datagen = ImageDataGenerator(rotation_range=90)\n",
    "    ans = datagen.flow(samples, batch_size=1)\n",
    "    ans = ans[0].astype(\"uint8\")\n",
    "    ans = np.squeeze(ans, 0)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create text similar to the original one with 5% of noise\n",
    "def syth_text(data, nptc=0.05):\n",
    "\n",
    "    ans = None\n",
    "    noise = np.random.normal(0, nptc, data.shape)\n",
    "    ans = data + noise\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to standarize the images in the dataset, it has 2 options\n",
    "def standarize_images(src_df, src_col, tgt_col, img_type, std_opt):\n",
    "    src_images = src_df[src_col]\n",
    "    tgt_images = list()\n",
    "\n",
    "    for timg in src_images:\n",
    "        # pcolor image\n",
    "        if img_type == \"rgb\":\n",
    "            timg = np.asarray(timg, dtype=\"object\")\n",
    "        \n",
    "        # b&w image\n",
    "        if img_type == \"rb\":\n",
    "            timg = np.asarray(timg) #, dtype=\"uint8\")\n",
    "            timg = timg[:,:,np.newaxis]\n",
    "            timg = np.asarray(timg, dtype=\"object\")\n",
    "        \n",
    "        # result 0.0 < std_timg < 1.0\n",
    "        if std_opt == \"std\":\n",
    "            std_timg = std_img(timg, 0, 255)\n",
    "\n",
    "        # result -1.0 < std_timg < 1.0\n",
    "        if std_opt == \"ctr\":\n",
    "            std_timg = ctr_std_img(timg, 0, 225)\n",
    "\n",
    "        tgt_images.append(std_timg)\n",
    "\n",
    "    src_df[tgt_col] = tgt_images\n",
    "    return src_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the max shape in the image dataset\n",
    "def get_mshape(shape_data, imgt):\n",
    "\n",
    "    max_x, max_y, max_ch = 0, 0, 0\n",
    "    shape_data = list(shape_data)\n",
    "    ans = None\n",
    "\n",
    "    if imgt == \"rgb\":\n",
    "\n",
    "        for tshape in shape_data:\n",
    "            tshape = eval(tshape)\n",
    "            tx, ty, tch = tshape[0], tshape[1], tshape[2]\n",
    "\n",
    "            if tx > max_x:\n",
    "                max_x = tx\n",
    "            if ty > max_y:\n",
    "                max_y = ty\n",
    "            if tch > max_ch:\n",
    "                max_ch = tch\n",
    "            \n",
    "        ans = (max_x, max_y, max_ch)\n",
    "    \n",
    "    elif imgt == \"bw\":\n",
    "\n",
    "        for tshape in shape_data:\n",
    "            tshape = eval(tshape)\n",
    "            tx, ty = tshape[0], tshape[1]\n",
    "\n",
    "            if tx > max_x:\n",
    "                max_x = tx\n",
    "            if ty > max_y:\n",
    "                max_y = ty\n",
    "            \n",
    "        ans = (max_x, max_y)\n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A UDF to convert input data into 3-D\n",
    "array as required for LSTM network.\n",
    "\n",
    "taken from https://towardsdatascience.com/step-by-step-understanding-lstm-autoencoder-layers-ffab055b6352\n",
    "'''\n",
    "def temporalize(data, lookback):\n",
    "    output_X = list()\n",
    "    for i in range(len(data)-lookback-1):\n",
    "        temp = list()\n",
    "        for j in range(1,lookback+1):\n",
    "            # Gather past records upto the lookback period\n",
    "            temp.append(data[[(i+j+1)], :])\n",
    "        temp = np.array(temp, dtype=\"object\")\n",
    "        output_X.append(temp)\n",
    "    output_X = np.array(output_X, dtype=\"object\")\n",
    "    return output_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the pandas df data into usable word dense vector representation, YOU NEED IT FOR THE CSV to be useful!\n",
    "def format_dvector(work_corpus):\n",
    "\n",
    "    ans = list()\n",
    "    for dvector in work_corpus:\n",
    "        dvector = eval(dvector)\n",
    "        dvector = np.asarray(dvector)\n",
    "        ans.append(dvector)\n",
    "    ans = np.asarray(ans, dtype=\"object\")\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funct to concatenate all label columns into one for a single y in ML training, returns a list\n",
    "def concat_labels(row, cname):\n",
    "\n",
    "    ans = list()\n",
    "    for c in cname:\n",
    "        r = row[c]\n",
    "        r = eval(r)\n",
    "        ans = ans + r\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save the ML model\n",
    "def save_model(model, m_path, m_file):\n",
    "\n",
    "    fpn = os.path.join(m_path, m_file)\n",
    "    fpn = fpn + \".h5\"\n",
    "    model.save(fpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the ML model\n",
    "def load_model(m_path, m_file):\n",
    "\n",
    "    fpn = os.path.join(m_path, m_file)\n",
    "    fpn = fpn + \".h5\"\n",
    "    model = keras.models.load_model(fpn)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to cast dataframe and avoid problems with keras\n",
    "def cast_batch(X_txt, X_img, y):\n",
    "    X_txt = np.asarray(X_txt).astype(\"float32\")\n",
    "    X_img = np.asarray(X_img).astype(\"float32\")\n",
    "    y = np.asarray(y).astype(\"float32\")\n",
    "    return X_txt, X_img, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to select real elements to train the discriminator\n",
    "def gen_real_samples(X_txt, X_img, y, sample_size, half_batch):\n",
    "\n",
    "    rand_index = np.random.randint(0, sample_size, size=half_batch)\n",
    "    Xt_real = X_txt[rand_index]\n",
    "    Xi_real = X_img[rand_index]\n",
    "    y_real = y[rand_index]\n",
    "    # noise = np.random.uniform(0.0, 0.05, size=y_real.shape)\n",
    "    # y_real = np.subtract(y_real, noise)\n",
    "    Xt_real, Xi_real, y_real = cast_batch(Xt_real, Xi_real, y_real)\n",
    "\n",
    "    return Xt_real, Xi_real, y_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create fake elements to train the discriminator\n",
    "def gen_fake_samples(gen_model, txt_shape, half_batch, cat_size):\n",
    "    # random text\n",
    "    Xt_fake = gen_latent_txt(txt_shape, half_batch)\n",
    "    # random generated image from the model\n",
    "    Xi_fake = gen_model.predict(Xt_fake)\n",
    "    # marking the images as fake in all accounts\n",
    "    y_fake = get_fake_negative(half_batch, cat_size)\n",
    "    # y_fake = np.zeros((half_batch, cat_size), dtype=\"float32\")\n",
    "    # casting data type\n",
    "    Xt_fake, Xi_fake, y_fake = cast_batch(Xt_fake, Xi_fake, y_fake)\n",
    "\n",
    "    return Xt_fake, Xi_fake, y_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create one fake + real samples to train the discriminator\n",
    "def complete_batch(Xt_real, Xi_real, y_real, Xt_fake, Xi_fake, y_fake):\n",
    "\n",
    "    # this batch needs txt to create images, the images themselves, and the images labels\n",
    "    Xt = np.concatenate((Xt_real, Xt_fake), axis=0)\n",
    "    Xi = np.concatenate((Xi_real, Xi_fake), axis=0)\n",
    "    y = np.concatenate((y_real, y_fake), axis=0)\n",
    "    # Xt, Xi, y = cast_batch(Xt, Xi, y)\n",
    "    \n",
    "    return Xt, Xi, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate random/latent text for image generator\n",
    "def gen_latent_txt(txt_shape, txt_samples):\n",
    "\n",
    "    ans = None\n",
    "    for i in range(txt_samples):\n",
    "\n",
    "        # be aware of this!!!!!!!\n",
    "        noise = np.random.normal(0.0, 1.0, size=txt_shape)\n",
    "        if ans is None:\n",
    "            txt = np.expand_dims(noise, axis=0)\n",
    "            ans = txt\n",
    "        else:\n",
    "            img = np.expand_dims(txt, axis=0)\n",
    "            ans = np.concatenate((ans, txt), axis=0)\n",
    "    # print(ans.shape)\n",
    "    # print(ans[0])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfunction to smooth the fake positives\n",
    "def smooth_positive_labels(y):\n",
    "\treturn y - 0.2 + (np.random.random(y.shape)*0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfunction to smooth the fake negatives\n",
    "def smooth_negative_labels(y):\n",
    "\treturn y + np.random.random(y.shape)*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly flip some labels\n",
    "def noisy_labels(y, p_flip):\n",
    "\t# determine the number of labels to flip\n",
    "\tn_select = int(p_flip * y.shape[0])\n",
    "\t# choose labels to flip\n",
    "\tflip_ix = np.random.choice([i for i in range(y.shape[0])], size=n_select)\n",
    "\t# invert the labels in place\n",
    "\ty[flip_ix] = 1 - y[flip_ix]\n",
    "\treturn y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fake true categories for the generator\n",
    "def get_fake_cat(batch_size, cat_size):\n",
    "\n",
    "    sz = (batch_size, cat_size)\n",
    "    ans = np.ones(sz)\n",
    "    # smooothing fakes\n",
    "    ans = smooth_positive_labels(ans)\n",
    "    ans = ans.astype(\"float32\")\n",
    "    # ans = np.ones((batch_size, cat_size), dtype=\"float32\")\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fake negative categories to train the GAN\n",
    "def get_fake_negative(batch_size, cat_size):\n",
    "\n",
    "    sz = (batch_size, cat_size)\n",
    "    ans = np.zeros(sz)\n",
    "    ans = smooth_negative_labels(ans)\n",
    "    ans = ans.astype(\"float32\")\n",
    "    # ans = np.ones((batch_size, cat_size), dtype=\"float32\")\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an expanded bath of images for training with some synthetic ones\n",
    "def gen_synthetic_images(X_img, img_size, batch_size, synth_size):\n",
    "\n",
    "    ans = None\n",
    "\n",
    "    # iterating the images and synth new ones\n",
    "    for img in X_img:\n",
    "        gen_img = None\n",
    "\n",
    "        # creating new ones\n",
    "        for j in range(synth_size):\n",
    "\n",
    "            if gen_img is None:\n",
    "                timg = syth_std_img(img)\n",
    "                timg = np.expand_dims(timg, axis=0)\n",
    "                gen_img = timg\n",
    "            \n",
    "            else:\n",
    "                timg = syth_std_img(img)\n",
    "                timg = np.expand_dims(timg, axis=0)\n",
    "                gen_img = np.concatenate((gen_img, timg), axis=0)\n",
    "        \n",
    "        # adding it to the training batch\n",
    "        if ans is None:\n",
    "            ans = gen_img\n",
    "\n",
    "        else:\n",
    "            ans = np.concatenate((ans, gen_img), axis=0)\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetizing a noisy std image from real data\n",
    "def syth_std_img(data):\n",
    "\n",
    "    samples = expand_dims(data, 0)\n",
    "    datagen = ImageDataGenerator(rotation_range=90)\n",
    "    ans = datagen.flow(samples, batch_size=1)\n",
    "    ans = ans[0].astype(\"float32\")\n",
    "    ans = np.squeeze(ans, 0)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to artificially span a batch with some noise and alterations by an specific number\n",
    "def expand_samples(X_txt, X_img, y, synth_batch):\n",
    "\n",
    "    # creating the exapnded batch response\n",
    "    Xe_txt, Xe_img, ye = None, None, None\n",
    "    \n",
    "    # iterating in the original batch\n",
    "    for Xtt, Xit, yt in zip(X_txt, X_img, y):\n",
    "\n",
    "        # temporal synth minibatch per original image\n",
    "        synth_Xt, synth_Xi, synth_y = None, None, None\n",
    "\n",
    "        # synthetizing artificial data for the batch\n",
    "        for i in range(synth_batch):\n",
    "\n",
    "            # generating first element\n",
    "            if (synth_Xt is None) and (synth_Xi is None) and (synth_y is None):\n",
    "                # gen text\n",
    "                gen_Xt = syth_text(Xtt)\n",
    "                gen_Xt = np.expand_dims(gen_Xt, axis=0)\n",
    "                synth_Xt = gen_Xt\n",
    "\n",
    "                # gen images\n",
    "                gen_Xi = syth_std_img(Xit)\n",
    "                gen_Xi = np.expand_dims(gen_Xi, axis=0)\n",
    "                synth_Xi = gen_Xi\n",
    "\n",
    "                # gen labels\n",
    "                gen_yt = syth_categories(y)\n",
    "                gen_yt = np.expand_dims(gen_yt, axis=0)\n",
    "                synth_y = gen_yt\n",
    "\n",
    "            # generatin the rest of the elements\n",
    "            else:\n",
    "                # gen text\n",
    "                gen_Xt = syth_text(Xtt)\n",
    "                gen_Xt = np.expand_dims(gen_Xt, axis=0)\n",
    "                synth_Xt = np.concatenate((synth_Xt, gen_Xt), axis=0)\n",
    "\n",
    "                # gen images\n",
    "                gen_Xi = syth_std_img(Xit)\n",
    "                gen_Xi = np.expand_dims(gen_Xi, axis=0)\n",
    "                synth_Xi = np.concatenate((synth_Xi, gen_Xi), axis=0)\n",
    "\n",
    "                # gen labels\n",
    "                gen_yt = syth_categories(y)\n",
    "                gen_yt = np.expand_dims(gen_yt, axis=0)\n",
    "                synth_y = np.concatenate((synth_y, gen_yt), axis=0)\n",
    "        \n",
    "        # adding the first part to the training batch\n",
    "        if ans is None:\n",
    "            # adding text\n",
    "            Xe_txt = synth_Xt\n",
    "            # adding images\n",
    "            Xe_img = synth_Xi\n",
    "            # adding categories\n",
    "            ye = synth_y\n",
    "\n",
    "        # adding the rest of the batch\n",
    "        else:\n",
    "            # adding text\n",
    "            Xe_txt = np.concatenate((Xe_txt, synth_Xt), axis=0)\n",
    "            # adding images\n",
    "            Xe_img = np.concatenate((Xe_img, synth_Xi), axis=0)\n",
    "            # adding categories\n",
    "            ye = np.concatenate((ye, synth_y), axis=0)\n",
    "\n",
    "    Xe_txt, Xe_img, ye = cast_batch(Xe_txt, Xe_img, ye)\n",
    "\n",
    "    return Xe_txt, Xe_img, ye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drift_labels(Xt_real, Xi_real, y_real, Xt_fake, Xi_fake, y_fake, batch_size, drift_pct):\n",
    "\n",
    "    # setting the size for the drift labels\n",
    "    drift_size = int(math.ceil(drift_pct*batch_size))\n",
    "    # random index for drift elements!!!\n",
    "    rand_drifters = np.random.choice(half_batch, size=drift_size, replace=False) \n",
    "    # print(\"random choise to change\", drift_size, \"\\n\", rand_drifters)\n",
    "\n",
    "    for drift in rand_drifters:\n",
    "\n",
    "        # copying temporal real data\n",
    "        Xt_drift = copy.deepcopy(Xt_real[drift])\n",
    "        Xi_drift = copy.deepcopy(Xi_real[drift])\n",
    "        y_drift = copy.deepcopy(y_real[drift])\n",
    "        # print(\"OG real y:\", y_drift)\n",
    "        # print(\"OG fake y:\", y_fake[drift])\n",
    "        \n",
    "        # replacing real with fakes\n",
    "        Xt_real[drift] = copy.deepcopy(Xt_fake[drift])\n",
    "        Xi_real[drift] = copy.deepcopy(Xi_fake[drift])\n",
    "        y_real[drift] = copy.deepcopy(y_fake[drift])\n",
    "        # print(\"New real y:\", y_real[drift])\n",
    "\n",
    "        # updating fakes with temporal original\n",
    "        Xt_fake[drift] = Xt_drift\n",
    "        Xi_fake[drift] = Xi_drift\n",
    "        y_fake[drift] = y_drift\n",
    "        # print(\"New fake y:\", y_fake[drift])\n",
    "\n",
    "    return Xt_real, Xi_real, y_real, Xt_fake, Xi_fake, y_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functioon to log the training results\n",
    "def test_model(epoch, gen_model, dis_model, X_txt, X_img, y, txt_shape, cat_shape, img_size, half_batch, report_fn_path, synth_batch):\n",
    "    # select real txt2img for discrimintator\n",
    "    Xt_real, Xi_real, y_real = gen_real_samples(X_txt, X_img, y, img_size, half_batch)\n",
    "    Xt_real, Xi_real, y_real = expand_samples(Xt_real, Xi_real, y_real, synth_batch)\n",
    "\n",
    "    # create false txt for txt2img for generator\n",
    "    Xt_fake, Xi_fake, y_fake = gen_fake_samples(gen_model, txt_shape, half_batch, cat_shape[0])\n",
    "    Xt_fake, Xi_fake, y_fake = expand_samples(Xt_fake, Xi_fake, y_fake, synth_batch)\n",
    "\n",
    "    # drift labels to confuse the model\n",
    "    Xt_real, Xi_real, y_real, Xt_fake, Xi_fake, y_fake = drift_labels(Xt_real, Xi_real, y_real, \n",
    "                                                                        Xt_fake, Xi_fake, y_fake, \n",
    "                                                                        half_batch, 0.05)\n",
    "    # evaluate model\n",
    "    testl_real = dis_model.evaluate(Xi_real, y_real, verbose=0)\n",
    "    testl_fake = dis_model.evaluate(Xi_fake, y_fake, verbose=0)\n",
    "\n",
    "    # summarize discriminator performance\n",
    "    print(\">>> Test Accuracy for fake samples: %.3f || fake samples: %.3f\" % (testl_fake[1], testl_fake[1]))\n",
    "    print(\">>> Test Loss for real samples: %.3f || fake samples: %.3f\" % (testl_real[0], testl_real[0]))\n",
    "    plot_gen_images(Xi_fake, epoch, report_fn_path, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gen_images(examples, epoch, report_fp_name, n_sample):\n",
    "\n",
    "    # get important data for iteratin\n",
    "    # examples = np.array(examples, dtype=\"float32\")\n",
    "    example_size = examples.shape[0]\n",
    "    og_shape = examples[0].shape\n",
    "    # rand_state = np.random.RandomState(42)\n",
    "    # choice\n",
    "    # rand_img = rand_state.choice(example_size, size=n_sample*n_sample, replace=False) \n",
    "    rand_img = np.random.choice(example_size, size=n_sample*n_sample, replace=False) \n",
    "    # (0, example_size, size=n_sample*n_sample)\n",
    "\n",
    "    # prep the figure\n",
    "    fig, ax = plt.subplots(n_sample,n_sample, figsize=(20,20))\n",
    "    fig.patch.set_facecolor(\"xkcd:white\")\n",
    "\n",
    "    # plot images\n",
    "    for i in range(n_sample*n_sample):\n",
    "        # define subplot\n",
    "        plt.subplot(n_sample, n_sample, 1+i)\n",
    "\n",
    "        # getting the images from sample\n",
    "        rand_i = rand_img[i]\n",
    "        gimg = examples[rand_i]\n",
    "        gimg = gimg*255\n",
    "        gimg = np.asarray(gimg).astype(\"uint8\")\n",
    "\n",
    "        # turn off axis\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(gimg) #, interpolation=\"nearest\")\n",
    "\n",
    "    # config axis\n",
    "    # ax.get_xaxis().set_visible(False)\n",
    "    # ax.get_yaxis().set_visible(False)\n",
    "    # plot leyend\n",
    "    fig.suptitle(\"GENERATED IMAGES\", fontsize=50)\n",
    "    fig.legend()\n",
    "\n",
    "    # save plot to file\n",
    "    plot_name = \"GAN-Gen-img-epoch%03d\" % int(epoch)\n",
    "    plot_name = plot_name + \".png\"\n",
    "    fpn = os.path.join(report_fp_name, plot_name)\n",
    "    plt.savefig(fpn)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a line plot of loss for the gan and save to file\n",
    "def plot_metrics(disr_hist, disf_hist, gan_hist, report_fp_name, epoch):\n",
    "\n",
    "    # reporting results\n",
    "    disr_hist = np.array(disr_hist)\n",
    "    disf_hist = np.array(disf_hist)\n",
    "    gan_hist = np.array(gan_hist)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16,8))\n",
    "    fig.patch.set_facecolor(\"xkcd:white\")\n",
    "\n",
    "    # loss\n",
    "    ax1.plot(disr_hist[:,1], \"royalblue\", label=\"Loss: R-Dis\")\n",
    "    ax1.plot(disf_hist[:,1], \"crimson\", label=\"Loss: F-Dis\")\n",
    "    ax1.plot(gan_hist[:,1], \"blueviolet\", label=\"Loss: GAN/Gen\")\n",
    "\n",
    "    # acc_\n",
    "    ax2.plot(disr_hist[:,0], \"royalblue\", label=\"Acc: R-Dis\")\n",
    "    ax2.plot(disf_hist[:,0], \"crimson\", label=\"Acc: F-Dis\")\n",
    "    ax2.plot(gan_hist[:,0], \"blueviolet\", label=\"Acc: GAN/Gem\")\n",
    "\n",
    "    # plot leyend\n",
    "    fig.suptitle(\"LEARNING BEHAVIOR\", fontsize=20)\n",
    "    ax1.grid(True)\n",
    "    ax2.grid(True)\n",
    "    ax1.set_title(\"Loss\")\n",
    "    ax2.set_title(\"Accuracy\")\n",
    "    ax1.set(xlabel = \"Epoch [cycle]\", ylabel = \"Loss\")\n",
    "    ax2.set(xlabel = \"Epoch [cycle]\", ylabel = \"Acc\")\n",
    "    fig.legend()\n",
    "\n",
    "    # save plot to file\n",
    "    plot_name = \"GAN-learn-curve-epoch%03d\" % int(epoch)\n",
    "    plot_name = plot_name + \".png\"\n",
    "    fpn = os.path.join(report_fp_name, plot_name)\n",
    "    plt.savefig(fpn)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the loss and accuracy avg in multiple batchs of an epoch\n",
    "def epoch_avg(log):\n",
    "    loss, acc = None, None\n",
    "\n",
    "    if len(log) > 0:\n",
    "\n",
    "        acc_list = list()\n",
    "        loss_list = list()\n",
    "\n",
    "        for l in log:\n",
    "\n",
    "            ta = l[0]\n",
    "            tl = l[1]\n",
    "\n",
    "            acc_list.append(ta)\n",
    "            loss_list.append(tl)\n",
    "\n",
    "        loss, acc = mean(loss_list), mean(acc_list)\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save model, needs the dirpath, the name and the datetime to save\n",
    "def export_model(model, models_fp_name, filename, datetime):\n",
    "\n",
    "    ss = True\n",
    "    sln = True\n",
    "    fext = \"png\"\n",
    "    fpn = filename + \"-\" + datetime\n",
    "    fpn = filename + \".\" + fext\n",
    "    fpn = os.path.join(models_fp_name, fpn)\n",
    "    plot_model(model, to_file=fpn, show_shapes=ss, show_layer_names=sln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to format data to save in file\n",
    "def format_metrics(disr_history, disf_history, gan_history):\n",
    "\n",
    "    headers, data = None, None\n",
    "\n",
    "    disr_hist = np.array(disr_history)\n",
    "    disf_hist = np.array(disf_history)\n",
    "    gan_hist = np.array(gan_history)\n",
    "\n",
    "    # formating file headers\n",
    "    headers = [\"dis_loss_real\", \"dis_acc_real\", \"dis_loss_fake\", \"dis_acc_fake\", \"gen_gan_loss\",\"gen_gan_acc\"]\n",
    "\n",
    "    # formating fake discriminator train data\n",
    "    drhl = disr_hist[:,1]# .flatten()\n",
    "    # drhl = drhl.tolist()\n",
    "    drha = disr_hist[:,0]# .flatten()\n",
    "    # drha = drha.tolist()\n",
    "\n",
    "    # formating real discrimintator train data\n",
    "    dfhl = disf_hist[:,1]# .flatten()\n",
    "    # dfhl = dfhl.tolist()\n",
    "    dfha = disf_hist[:,0]# .flatten()\n",
    "    # dfha = dfha.tolist()\n",
    "\n",
    "    # formating gan/gen train data\n",
    "    gghl = gan_hist[:,1]# .flatten()\n",
    "    # gghl = gghl.tolist()\n",
    "    ggha = gan_hist[:,0]#.flatten()\n",
    "    # ggha = ggha.tolist()\n",
    "\n",
    "    # adding all formatted data into list\n",
    "    data = np.column_stack((drhl, drha, dfhl, dfha, gghl, ggha))\n",
    "    # data = pd.DataFrame(values, columns=headers)\n",
    "    return data, headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to write data in csv file\n",
    "def write_metrics(data, headers, report_fp_name, filename):\n",
    "\n",
    "    # print(report_fp_name, filename)\n",
    "    fpn = filename + \"-train-history.csv\"\n",
    "    fpn = os.path.join(report_fp_name, fpn)\n",
    "\n",
    "    history_df = pd.DataFrame(data, columns=headers)\n",
    "    tdata = history_df.to_csv(\n",
    "                            fpn,\n",
    "                            sep=\",\",\n",
    "                            index=False,\n",
    "                            encoding=\"utf-8\",\n",
    "                            mode=\"w\",\n",
    "                            quoting=csv.QUOTE_ALL\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to safe the loss/acc logs in training for the gan/gen/dis models\n",
    "def save_metrics(disr_history, disf_history, gan_history, report_fp_name, filename):\n",
    "\n",
    "    data, headers = format_metrics(disr_history, disf_history, gan_history)\n",
    "    write_metrics(data, headers, report_fp_name, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to know the time between epochs or batchs it return the new time for a new calculation\n",
    "def lapse_time(last_time, epoch):\n",
    "\n",
    "    now_time = datetime.datetime.now()\n",
    "    deltatime = now_time - last_time\n",
    "    deltatime = deltatime.total_seconds()\n",
    "    deltatime = \"%.2f\" % deltatime\n",
    "    msg = \"Epoch:%3d \" % int(epoch+1)\n",
    "    msg = msg + \"elapsed time: \" + str(deltatime) + \" [s]\"\n",
    "    print(msg)\n",
    "    return now_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special function to train the GAN\n",
    "# https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/\n",
    "def train(gen_model, dis_model, gan_model, X_img, X_txt, y, epochs, batch_size, save_intervas, fn_config):\n",
    "\n",
    "    # sample shape\n",
    "    txt_shape = X_txt[0].shape\n",
    "    img_shape = X_img[0].shape\n",
    "    cat_shape = y[0].shape\n",
    "\n",
    "    # sample size\n",
    "    txt_size = X_txt.shape[0]\n",
    "    img_size = X_img.shape[0]\n",
    "    cat_size = y.shape[0]\n",
    "    synth_batch = 4\n",
    "    n = 3\n",
    "\n",
    "    # model IO configuration\n",
    "    model_fn_path = fn_config[0]\n",
    "    report_fn_path = fn_config[1]\n",
    "    dis_model_name = fn_config[2]\n",
    "    gen_model_name = fn_config[3]\n",
    "    gan_model_name = fn_config[4]\n",
    "\n",
    "    # fake/real batch division\n",
    "    half_batch = int(batch_size/2)\n",
    "    batch_per_epoch = int(txt_size/batch_size)\n",
    "    real_batch = int(batch_size*synth_batch)\n",
    "\n",
    "\t# prepare lists for storing stats each epoch\n",
    "    # disf_hist, disr_hist, gen_hist, gan_hist = list(), list(), list(), list()\n",
    "    disf_hist, disr_hist, gan_hist = list(), list(), list()\n",
    "    train_time = None\n",
    "    # iterating in training epochs:\n",
    "    for ep in range(epochs):\n",
    "        # epoch logs\n",
    "        # ep_disf_hist, ep_disr_hist, ep_gen_hist, ep_gan_hist = list(), list(), list(), list()\n",
    "        ep_disf_hist, ep_disr_hist, ep_gan_hist = list(), list(), list()\n",
    "        train_time = datetime.datetime.now()\n",
    "\n",
    "        # iterating over training batchs\n",
    "        for batch in range(batch_per_epoch):\n",
    "\n",
    "            # select real txt2img for discrimintator\n",
    "            Xt_real, Xi_real, y_real = gen_real_samples(X_txt, X_img, y, img_size, half_batch)\n",
    "            # expand the training sample for the discriminator\n",
    "            Xt_real, Xi_real, y_real = expand_samples(X_txt, X_img, y, synth_batch)\n",
    "\n",
    "            # create false txt for txt2img for generator\n",
    "            Xt_fake, Xi_fake, y_fake = gen_fake_samples(gen_model, txt_shape, half_batch, cat_shape[0])\n",
    "            # expand the training sample for the discriminator\n",
    "            Xt_fake, Xi_fake, y_fake = expand_samples(Xt_fake, Xi_fake, y_fake, synth_batch)\n",
    "\n",
    "            # drift labels to confuse the model\n",
    "            Xt_real, Xi_real, y_real, Xt_fake, Xi_fake, y_fake = drift_labels(Xt_real, Xi_real, y_real, \n",
    "                                                                                Xt_fake, Xi_fake, y_fake,\n",
    "                                                                                real_batch, 0.05)\n",
    "    \n",
    "            # train for real samples batch\n",
    "            dhr = dis_model.train_on_batch(Xi_real, y_real)\n",
    "            # train for fake samples batch\n",
    "            dhf = dis_model.train_on_batch(Xi_fake, y_fake)\n",
    "\n",
    "            # prepare noisy text of latent space as input for the generator\n",
    "            Xt_gen = gen_latent_txt(txt_shape, batch_size)\n",
    "            # create inverted labels for the fake noisy text\n",
    "            y_gen = get_fake_cat(batch_size, cat_shape[0])\n",
    "            # update the generator via the discriminator's error\n",
    "            gh = gan_model.train_on_batch(Xt_gen, y_gen)\n",
    "            # print(\"ojo GAN!\", gh)\n",
    "\n",
    "            ep_disr_hist.append(dhf)\n",
    "            ep_disf_hist.append(dhr)\n",
    "            # ep_gen_hist.append(gh)\n",
    "            ep_gan_hist.append(gh)\n",
    "\n",
    "\t\t\t# print('>%d, %d/%d, dis_=%.3f, gen=%.3f' % (ep+1, batch+1, bat_per_epo, dis_history, gen_history))\n",
    "            log_msg = \">>> Epoch: %d, B/Ep: %d/%d, Batch S: %d\" % (ep+1, batch+1, batch_per_epoch, batch_size)\n",
    "            log_msg = \"%s -> [R-Dis loss: %.3f, acc: %.3f]\" % (log_msg, dhr[0], dhr[1])\n",
    "            log_msg = \"%s || [F-Dis loss: %.3f, acc: %.3f]\" % (log_msg, dhf[0], dhf[1])\n",
    "            log_msg = \"%s || [Gen loss: %.3f, acc: %.3f]\" % (log_msg, gh[0], gh[1])\n",
    "            print(log_msg)\n",
    "\n",
    "        # record history for epoch\n",
    "        disr_hist.append(epoch_avg(ep_disr_hist))\n",
    "        disf_hist.append(epoch_avg(ep_disf_hist))\n",
    "        # gen_hist.append(epoch_avg(ep_gen_hist))\n",
    "        gan_hist.append(epoch_avg(ep_gan_hist))\n",
    "\n",
    "\t\t# evaluate the model performance sometimes\n",
    "        if (ep) % save_intervas == 0:\n",
    "            print(\"Epoch:\", ep+1, \"Saving the training progress...\")\n",
    "\n",
    "            test_model(ep, gen_model, dis_model, X_txt, X_img, y, txt_shape, cat_shape, img_size, half_batch, report_fn_path, synth_batch)\n",
    "            plot_metrics(disr_hist, disf_hist, gan_hist, report_fn_path, ep)\n",
    "            save_metrics(disr_hist, disf_hist, gan_hist, report_fn_path, gan_model_name)\n",
    "\n",
    "\t\t# saving the model sometimes\n",
    "        if (ep) % int(save_intervas*5) == 0:\n",
    "            # epoch_sufix = \"-epoch%3d\" % int(ep)\n",
    "            epoch_sufix = \"-last\"\n",
    "            epoch_sufix = str(epoch_sufix)\n",
    "            dis_mn = dis_model_name + epoch_sufix\n",
    "            gen_mn = gen_model_name + epoch_sufix\n",
    "            gan_mn = gan_model_name + epoch_sufix\n",
    "\n",
    "            dis_path = os.path.join(model_fn_path, \"Dis\")\n",
    "            gen_path = os.path.join(model_fn_path, \"Gen\")\n",
    "            gan_path = os.path.join(model_fn_path, \"GAN\")\n",
    "\n",
    "            save_model(dis_model, dis_path, dis_mn)\n",
    "            save_model(gen_model, gen_path, gen_mn)\n",
    "            save_model(gan_model, gan_path, gan_mn)\n",
    "        \n",
    "        train_time = lapse_time(train_time, ep)"
   ]
  },
  {
   "source": [
    "# EXEC SCRIPT\n",
    "\n",
    "## Dataset prep"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable definitions\n",
    "# root folder\n",
    "dataf = \"Data\"\n",
    "\n",
    "# subfolder with predictions txt data\n",
    "imagef = \"Img\"\n",
    "\n",
    "# report subfolder\n",
    "reportf = \"Reports\"\n",
    "\n",
    "#  subfolder with the CSV files containing the ML pandas dataframe\n",
    "trainf = \"Train\"\n",
    "testf = \"Test\"\n",
    "\n",
    "# subfolder for model IO\n",
    "modelf = \"Models\"\n",
    "\n",
    "# dataframe file extension\n",
    "fext = \"csv\"\n",
    "\n",
    "imgf = \"jpg\"\n",
    "\n",
    "rgb_sufix = \"rgb\"\n",
    "bw_sufix = \"bw\"\n",
    "\n",
    "# standard sufix\n",
    "stdprefix = \"std-\"\n",
    "\n",
    "# ml model useful data\n",
    "mltprefix = \"ml-\"\n",
    "\n",
    "# report names\n",
    "# timestamp = datetime.date.today().strftime(\"%d-%b-%Y\")\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "sample_sufix = \"Small\"\n",
    "# sample_sufix = \"Large\"\n",
    "# sample_sufix = \"Paintings\"\n",
    "imgf_sufix = \"Img-Data-\"\n",
    "text_sufix = \"Text-Data-\"\n",
    "\n",
    "# std-VVG-Gallery-Text-Data-Paintings\n",
    "gallery_prefix = \"VVG-Gallery-\"\n",
    "\n",
    "# dataframe file name\n",
    "text_fn = stdprefix + gallery_prefix + text_sufix + sample_sufix + \".\" + fext\n",
    "imgf_fn = stdprefix + gallery_prefix + imgf_sufix + sample_sufix + \".\" + fext\n",
    "valt_fn = \"Validation-GAN-\" + text_sufix + sample_sufix + \".\" + fext\n",
    "\n",
    "# model names\n",
    "dis_model_name = \"VVG-Text2Img-Discriminator\"\n",
    "gen_model_name = \"VVG-Text2Img-Generator\"\n",
    "gan_model_name = \"VVG-Text2Img-GAN\"\n",
    "\n",
    "# to continue training after stoping script\n",
    "continue_training = True\n",
    "\n",
    "# ramdom seed\n",
    "randseed = 42\n",
    "\n",
    "# sample distribution train vs test sample size\n",
    "train_split = 0.80\n",
    "test_split = 1.0 - train_split\n",
    "\n",
    "# regex to know that column Im interested in\n",
    "keeper_regex = r\"(^ID$)|(^std_)\"\n",
    "\n",
    "imgt = rgb_sufix\n",
    "# imgt = bw_sufix\n",
    "\n",
    "# woring values for code\n",
    "work_txtf, work_imgf, work_sufix, work_imgt = text_fn, imgf_fn, sample_sufix, imgt\n",
    "\n",
    "print(\"=== working files ===\")\n",
    "print(\"\\n\", work_txtf, \"\\n\", work_imgf, \"\\n\", work_sufix, \"\\n\", work_imgt, \"\\n\", valt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = os.getcwd()\n",
    "root_folder = os.path.split(root_folder)[0]\n",
    "root_folder = os.path.normpath(root_folder)\n",
    "print(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable reading\n",
    "# dataframe filepath for texttual data\n",
    "text_fn_path = os.path.join(root_folder, dataf, trainf, work_txtf)\n",
    "print(text_fn_path, os.path.exists(text_fn_path))\n",
    "\n",
    "# dataframe filepath for img data\n",
    "img_fn_path = os.path.join(root_folder, dataf, trainf, work_imgf)\n",
    "print(img_fn_path, os.path.exists(img_fn_path))\n",
    "\n",
    "# dataframe filepath form GAN data\n",
    "val_fn_path = os.path.join(root_folder, dataf, testf, valt_fn)\n",
    "print(val_fn_path, os.path.exists(val_fn_path))\n",
    "\n",
    "# filepath for the models\n",
    "model_fn_path = os.path.join(root_folder, dataf, modelf)\n",
    "print(model_fn_path, os.path.exists(model_fn_path))\n",
    "\n",
    "# filepath for the reports\n",
    "report_fn_path = os.path.join(root_folder, dataf, reportf)\n",
    "print(report_fn_path, os.path.exists(report_fn_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rading training data\n",
    "# loading textual file\n",
    "text_df = pd.read_csv(\n",
    "                text_fn_path,\n",
    "                sep=\",\",\n",
    "                encoding=\"utf-8\",\n",
    "                engine=\"python\",\n",
    "            )\n",
    "text_cols = text_df.columns.values\n",
    "\n",
    "# loading image file\n",
    "img_df = pd.read_csv(\n",
    "                img_fn_path,\n",
    "                sep=\",\",\n",
    "                encoding=\"utf-8\",\n",
    "                engine=\"python\",\n",
    "            )\n",
    "img_cols = img_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_cols = list()\n",
    "\n",
    "for tcol in text_cols:\n",
    "    if tcol in img_cols:\n",
    "        idx_cols.append(tcol)\n",
    "print(idx_cols)\n",
    "\n",
    "source_df = pd.merge(text_df, img_df, how=\"inner\", on=idx_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking everything is allrigth\n",
    "img_df = None\n",
    "text_df = None\n",
    "source_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = source_df.set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading images from folder and loading images into df\n",
    "# working variables\n",
    "src_col = work_imgt + \"_img\"\n",
    "tgt_col = work_imgt + \"_img\" + \"_data\"\n",
    "work_shape = work_imgt + \"_shape\"\n",
    "\n",
    "print(src_col, tgt_col)\n",
    "source_df = get_images(root_folder, source_df, src_col, tgt_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# synthetic data augmentation\n",
    "# source_df = augment_images(source_df, src_col, tgt_col, 6)\n",
    "# source_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching the biggest shape in the image files\n",
    "print(work_shape)\n",
    "shape_data = source_df[work_shape]\n",
    "max_shape = get_mshape(shape_data, work_imgt)\n",
    "print(max_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# padding training data according to max shape of the images in gallery\n",
    "pad_prefix = \"pad_\"\n",
    "conv_prefix = \"cnn_\"\n",
    "src_col = work_imgt + \"_img\" + \"_data\"\n",
    "tgt_col = pad_prefix + conv_prefix + src_col\n",
    "\n",
    "print(src_col, tgt_col, work_imgt)\n",
    "source_df = padding_images(source_df, src_col, tgt_col, max_shape, work_imgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading images from folder and stadarizing images into df\n",
    "# working variables\n",
    "print(\"standarizing regular images...\")\n",
    "src_col = work_imgt + \"_img\" + \"_data\"\n",
    "tgt_col = \"std_\" + src_col\n",
    "\n",
    "# source_df = standarize_images(source_df, src_col, tgt_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"standarizing padded images...\")\n",
    "src_col = pad_prefix + conv_prefix + work_imgt + \"_img\" + \"_data\"\n",
    "tgt_col = \"std_\" + src_col\n",
    "print(src_col, tgt_col)\n",
    "std_opt = \"std\"\n",
    "source_df = standarize_images(source_df, src_col, tgt_col, work_imgt, std_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the DataFrame rows\n",
    "source_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting data to train\n",
    "# want to keep the columns starting with STD_\n",
    "df_columns = list(source_df.columns)\n",
    "print(\"------ original input/interested columns ------\")\n",
    "print(df_columns)\n",
    "\n",
    "# create the columns Im interesting in\n",
    "keep_columns = [i for i in df_columns if re.search(keeper_regex, i)]\n",
    "\n",
    "print(\"\\n\\n------ Interesting columns ------\")\n",
    "print(keep_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of max num on labels in the categories\n",
    "too_disperse = list()\n",
    "max_dis = 2\n",
    "tcount = 0\n",
    "\n",
    "while tcount < max_dis:\n",
    "    for label_col in keep_columns:\n",
    "\n",
    "        if label_col != \"std_pad_cnn_rgb_img_data\":\n",
    "\n",
    "            label_count = source_df[label_col].value_counts(normalize=False)\n",
    "\n",
    "            if tcount < label_count.shape[0] and (\"std_cat_\" in label_col):\n",
    "                tcount = label_count.shape[0]\n",
    "                too_disperse.append(label_col)\n",
    "\n",
    "            print(\"count values of\", label_col, \":=\", label_count.shape)#.__dict__)\n",
    "    tcount = tcount + 1\n",
    "\n",
    "print(too_disperse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the training dataframe\n",
    "for too in too_disperse:\n",
    "    keep_columns.remove(too)\n",
    "# keep_columns.remove(\"ID\")\n",
    "print(\"------ Interesting columns ------\")\n",
    "print(keep_columns)\n",
    "train_df = pd.DataFrame(source_df, columns=keep_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.info()\n",
    "train_df = train_df.sample(frac = 1)\n",
    "source_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the column with the relevant data to train\n",
    "padimg_col = [i for i in df_columns if re.search(u\"^std_pad_\", i)]\n",
    "padimg_col = padimg_col[0]\n",
    "print(\"Padded image column in dataframe: \", str(padimg_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the column with the relevant data to train\n",
    "dvector_col = [i for i in df_columns if re.search(u\"^std_dvec\", i)]\n",
    "dvector_col = dvector_col[0]\n",
    "print(\"Dense vector column in dataframe: \", str(dvector_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix column data type\n",
    "work_corpus = train_df[dvector_col]\n",
    "work_corpus = format_dvector(work_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing type in dataframe\n",
    "train_df[dvector_col] = work_corpus\n",
    "work_corpus = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding training data according to max length of text corpus\n",
    "pad_prefix = \"pad_\"\n",
    "recurrent_prefix = \"lstm_\"\n",
    "\n",
    "# getting the corpus dense vectors\n",
    "work_corpus = np.asarray(train_df[dvector_col], dtype=\"object\")\n",
    "\n",
    "# converting list of list to array of array\n",
    "print(work_corpus.shape)\n",
    "print(type(work_corpus[0]))\n",
    "\n",
    "# padding the representation\n",
    "work_corpus = pad_sequences(work_corpus, dtype='object', padding=\"post\")\n",
    "print(work_corpus.shape)\n",
    "\n",
    "# creating the new column and saving padded data\n",
    "padded_col_dvector = pad_prefix + dvector_col\n",
    "\n",
    "# print(padded_col)\n",
    "train_df[padded_col_dvector] = list(work_corpus)\n",
    "print(work_corpus.shape)\n",
    "work_corpus = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_img_col = \"std_\" + work_imgt + \"_img\" + \"_data\"\n",
    "padded_img_col = \"std_\" + pad_prefix + conv_prefix + work_imgt + \"_img\" + \"_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the columns with the relevant labels to predict\n",
    "print(keep_columns)\n",
    "labels_cols = [i for i in keep_columns if re.search(u\"^std_cat_\", i)]\n",
    "print(\"Trainable labels columns in dataframe: \", str(labels_cols))\n",
    "\n",
    "labels_data = train_df[labels_cols]\n",
    "labels_concat = list()\n",
    "\n",
    "# concatenating all category labels from dataframe\n",
    "for index, row in labels_data.iterrows():\n",
    "    row = concat_labels(row, labels_cols)\n",
    "    labels_concat.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(labels_concat[0]), type(labels_concat[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating dataframe\n",
    "tcat_label_col = \"std_cat_labels\"\n",
    "train_df[tcat_label_col] = labels_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lstm_col = padded_col_dvector\n",
    "print(text_lstm_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_img_col = padded_img_col\n",
    "# working_img_col = regular_img_col\n",
    "print(working_img_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating Train/Test sample\n",
    "# getting the X, y to train, as is autoencoder both are the same\n",
    "og_shape = train_df[working_img_col][0].shape# y[0].shape\n",
    "X_img_len = train_df[working_img_col].shape[0] #y.shape[0]\n",
    "print(X_img_len, og_shape)\n",
    "\n",
    "X_img = None\n",
    "\n",
    "for img in train_df[working_img_col]:\n",
    "\n",
    "    if X_img is None:\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        X_img = img\n",
    "    else:\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        X_img = np.concatenate((X_img, img), axis=0)\n",
    "\n",
    "print(\"final X_img shape\", X_img.shape)\n",
    "# y.shape = (1899, 800, 800, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_img[0]))\n",
    "print(type(X_img[0][0]))\n",
    "print(X_img[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X_img.shape) == 3:\n",
    "    X_img = X_img[:,:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = train_df[working_img_col]\n",
    "# y = np.expand_dims(y, axis=0)\n",
    "y = np.asarray([np.asarray(j, dtype=\"object\") for j in train_df[tcat_label_col]], dtype=\"object\")\n",
    "print(\"y shape\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.ones((y.shape[0],1)).astype(\"float32\")\n",
    "# print(test.shape, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y[0]))\n",
    "print(type(y[0][0]))\n",
    "print(y[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Train/Test sample\n",
    "# getting the X, y to train, as is autoencoder both are the same\n",
    "X_txt = np.asarray([np.asarray(i, dtype=\"object\") for i in train_df[text_lstm_col]], dtype=\"object\")\n",
    "# X = np.array(train_df[text_lstm_col]).astype(\"object\")\n",
    "# X = train_df[text_lstm_col]\n",
    "print(\"final X_lstm shape\", X_txt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_txt[0]))\n",
    "print(type(X_txt[0][0]))\n",
    "print(X_txt[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestep is the memory of what i read, this is the longest sentence I can remember in the short term\n",
    "# neet to look for the best option, in small the max is 15\n",
    "timesteps = 15\n",
    "\n",
    "# features is the max length in the corpus, after padding!!!!\n",
    "features = X_txt[0].shape[0]\n",
    "print(timesteps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_txt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation for reshape lstm model\n",
    "X_txt = temporalize(X_txt, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_txt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_txt = X_txt.reshape((X_txt.shape[0], timesteps, features))\n",
    "print(X_txt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_txt = y.shape[0] - X_txt.shape[0]\n",
    "print(diff_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa = X_txt[-diff_txt:]\n",
    "X_txt = np.append(X_txt, Xa, axis=0)\n",
    "print(X_txt.shape)\n",
    "Xa = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_txt.shape)\n",
    "print(X_img.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_txt[0].shape)\n",
    "print(X_img[0].shape)\n",
    "print(y[0].shape)\n",
    "txt_og_shape = X_txt[0].shape\n",
    "img_og_shape = X_img[0].shape\n",
    "cat_og_shape = y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xt = X_txt # np.array(X).astype(\"object\")\n",
    "# Xi = X_img\n",
    "# yt = y # np.array(y).astype(\"object\")\n",
    "# # ya = y[0:timesteps]\n",
    "# train_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "source": [
    "## ML Model Definition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of neurons or processing units in LSTM\n",
    "# the number is because of good practices for NLP\n",
    "# min 200 max 500, normaly 300 (related to the semantic number of themes)\n",
    "# 120 for now in this test\n",
    "lstm_units = 500\n",
    "print(\"Generator LSMT neurons:\", lstm_units)\n",
    "\n",
    "# timestep is 1 because you read a word at a time\n",
    "memory = timesteps\n",
    "print(\"Generator LSTM memory span:\", memory)\n",
    "# configuration to remember previous recurrent layer\n",
    "rs = True\n",
    "\n",
    "# features is the max length in the corpus, after padding!!!!\n",
    "# print(X_train.shape)\n",
    "features = X_txt.shape[2]\n",
    "print(\"Generator LSTM learning features:\", features)\n",
    "\n",
    "# batch size\n",
    "bs = 32\n",
    "print(\"Discriminator & Generator learning batch size:\", bs)\n",
    "\n",
    "# number of filters or processing units in CNN\n",
    "# the number is because of good practices from computer vision\n",
    "# min 8 max 64, normaly 32 (related to the size of the images)\n",
    "# 16 for now in this test\n",
    "# imgage filters\n",
    "filters = 16\n",
    "print(\"Generator CNN filter number:\", filters)\n",
    "\n",
    "disin_shape = X_img[0].shape\n",
    "genout_shape = X_img[0].shape\n",
    "# in_shape = (None, None, 1)\n",
    "# in_shape = (794, 794, 3)\n",
    "print(\"Discriminator Input shape:\", disin_shape)\n",
    "print(\"Generator Output shape:\", genout_shape)\n",
    "\n",
    "ksize = (3,3) \n",
    "# ksize = (5,5)\n",
    "stsize = (1,1)\n",
    "# stsize = (2,2)\n",
    "psize = (2,2)\n",
    "# psize = (4,4)\n",
    "\n",
    "print(\"Discriminator & Generator CNN kernel size:\", ksize)\n",
    "print(\"Discriminator & Generator CNN pad size:\", psize)\n",
    "\n",
    "# neurons/processing units size in the dense layer (THIS SHOULD BE SOM!!!!)\n",
    "gen_midn = 100*100*3 # 50*50*3\n",
    "gen_reshape = (100,100,3) # (50,50,3)\n",
    "print(\"Generator Dense middle neurons:\", gen_midn)\n",
    "# dn2 = len(XB_set[0])*SECURITY_FACTOR\n",
    "\n",
    "# numero de neuronas de salida\n",
    "# out_shape = X_train[0].shape\n",
    "# out_shape = (None, None, 3)\n",
    "# out_shape = in_shape\n",
    "out_dis = y[0].shape[0]\n",
    "# out_dis = y[0].shape\n",
    "print(\"Discriminator Output prediction labels:\", out_dis)\n",
    "\n",
    "channels = img_og_shape[2]\n",
    "# channels = 8\n",
    "# dis_midn = filters*out_dis*channels*15*5\n",
    "dis_midn = filters*channels*out_dis*2\n",
    "print(\"Discriminator Dense middle neurons:\", dis_midn)\n",
    "\n",
    "# axtivation functions\n",
    "in_dis_actf = LeakyReLU(alpha=0.2) # \"relu\"\n",
    "in_gen_actf = LeakyReLU(alpha=0.2) # \"relu\"\n",
    "hid_ly_actf = LeakyReLU(alpha=0.2) # \"relu\",\n",
    "out_dis_act = \"sigmoid\" # \"softmax\"\n",
    "out_gen_act = \"softmax\" # \"tanh\"\n",
    "\n",
    "# loss percentage\n",
    "dis_ldrop = 0.3\n",
    "gen_ldrop = 0.2\n",
    "\n",
    "# padding policy\n",
    "pad = \"same\"\n",
    "\n",
    "# random seed\n",
    "randseed = 42\n",
    "\n",
    "# parameters to compile model\n",
    "# loss function\n",
    "# ls = \"mean_squared_error\"\n",
    "# ls = \"categorical_crossentropy\"\n",
    "ls = \"binary_crossentropy\"\n",
    "\n",
    "# dis & gan/gen optimization function\n",
    "# Adam option\n",
    "dis_opti = Adam(learning_rate=0.00020, beta_1=0.5)\n",
    "gan_opti = Adam(learning_rate=0.00030, beta_1=0.5)\n",
    "# gan_opti = Adam(learning_rate=0.00020, beta_1=0.5)\n",
    "\n",
    "# Adadelta option\n",
    "# gan_opti = Adadelta(learning_rate=0.00030)\n",
    "\n",
    "# Adagrad option\n",
    "# gan_opti = Adagrad(learning_rate=0.0002, momentum=0.5)\n",
    "# gan_opti = Adagrad(learning_rate=0.0003, momentum=0.5)\n",
    "\n",
    "# evaluation score\n",
    "# met = [\"categorical_accuracy\"]\n",
    "met = [\"accuracy\"]\n",
    "\n",
    "# parameters to exeute training\n",
    "# verbose mode\n",
    "ver = 0\n",
    "# training epocha\n",
    "epo = 500\n",
    "print(\"training epochs:\", epo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator layers\n",
    "# 1) Mask -> Drop -> LSTM1 -> LSTM2 -> LSTM3 -> Drop -> Dense -> Drop -> LSTM3 -> LSTM2 -> LSTM1 -> Drop -> TimeDistDense\n",
    "gen_layers = (\n",
    "\n",
    "    # input layer (padding and prep)\n",
    "    Masking(mask_value=0.0, input_shape=(memory, features), name = \"LayMask\"),\n",
    "\n",
    "    # intermediate recurrent encoder layer\n",
    "    LSTM(lstm_units, activation=in_gen_actf, input_shape=(memory, features), return_sequences=rs, name=\"EnLSTM_1\"),\n",
    "    # SpatialDropout1D(gen_ldrop, name = \"EnDrop_1\"),\n",
    "    Dropout(gen_ldrop, name=\"EnDrop_1\"),\n",
    "\n",
    "    # intermediate recurrent encoder layer\n",
    "    LSTM(int(lstm_units/2), activation=hid_ly_actf, input_shape=(timesteps, features), return_sequences=rs, name=\"EnLSTM_2\"),\n",
    "    # Dropout(gen_ldrop, name=\"EnDrop_2\"),\n",
    "\n",
    "    # intermediate recurrent encoder layer\n",
    "    LSTM(int(lstm_units/4), activation=hid_ly_actf, input_shape=(timesteps, features), return_sequences=rs, name=\"EnLSTM_3\"),\n",
    "    Dropout(gen_ldrop, name=\"EnDrop_3\"),\n",
    "\n",
    "    # #from 2D to 1D\n",
    "    Flatten(name=\"LayFlat\"),\n",
    "    # mid dense encoding layer\n",
    "    Dense(gen_midn, activation=hid_ly_actf, name=\"MidDense\"),\n",
    "    # # from 1D to 2D\n",
    "    Reshape(gen_reshape, name=\"layReshape\"),\n",
    "\n",
    "    # intermediate convolutional decoder layer\n",
    "    Conv2D(int(filters/4), ksize, strides=stsize, activation=hid_ly_actf, padding=pad, name=\"DeConv_2\"),\n",
    "    # Conv2DTranspose(int(filters/4), kernel_size=ksize, activation=act, padding = pad, name=\"DeConvT2\"),\n",
    "    UpSampling2D(psize, name=\"DeUpsam_2\"),\n",
    "    Dropout(gen_ldrop, name=\"DeDrop_2\"),\n",
    " \n",
    "    # intermediate convolutional decoder layer\n",
    "    Conv2D(int(filters/2), ksize, strides=stsize, activation=hid_ly_actf, padding=pad, name=\"DeConv_3\"),\n",
    "    # Conv2DTranspose(int(filters/2), kernel_size=ksize, activation = act, padding = pad, name = \"DeConvT3\"),\n",
    "    UpSampling2D(psize, name=\"DeUpsam_3\"),\n",
    "    # Dropout(gen_ldrop, name=\"DeDrop_3\"),\n",
    "\n",
    "    # intermediate convolutional decoder layer\n",
    "    Conv2D(filters, ksize, strides=stsize, activation=hid_ly_actf, padding=pad, name=\"DeConv_4\"),\n",
    "    # Conv2DTranspose(filters, kernel_size=ksize, activation = act, padding = pad, name = \"DeConvT4\"),\n",
    "    UpSampling2D(psize, name=\"DeUpsam_4\"),\n",
    "    Dropout(gen_ldrop, name=\"DeDrop_4\"),\n",
    "\n",
    "    # outputlayer\n",
    "    # Conv2D(3, ksize, strides=stsize, activation=act, padding=pad, name=\"LayOut\"),\n",
    "    Conv2D(channels, ksize, strides=stsize, activation=out_gen_act, input_shape=genout_shape, padding=pad, name=\"LayOut\"),\n",
    ")"
   ]
  },
  {
   "source": [
    "# defining model\n",
    "gen_model = Sequential(gen_layers)\n",
    "gen_model.model_name = gen_model_name"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT compile model\n",
    "# gen_model.compile(loss=ls, optimizer=gan_opti, metrics=met)\n",
    "gen_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator layers\n",
    "# 1) Mask -> Drop -> LSTM1 -> LSTM2 -> LSTM3 -> Drop -> Dense -> Drop -> LSTM3 -> LSTM2 -> LSTM1 -> Drop -> TimeDistDense\n",
    "dis_layers = (\n",
    "    # input layer (padding and prep)\n",
    "    Input(shape=disin_shape, name=\"LayIn\"),\n",
    "\n",
    "    # intermediate convolutional encoder layer\n",
    "    Conv2D(filters, ksize, strides=stsize, activation=hid_ly_actf, padding=pad, name=\"EnConv_1\"),\n",
    "    MaxPooling2D(psize, padding=pad, name=\"EnPool_1\"),\n",
    "    Dropout(dis_ldrop, name=\"EnDrop_1\"),\n",
    "\n",
    "    # intermediate convolutional encoder layer\n",
    "    Conv2D(int(filters/2), ksize, strides=stsize, activation=hid_ly_actf, padding=pad, name=\"EnConv_2\"),\n",
    "    MaxPooling2D(psize, padding=pad, name=\"EnPool_2\"),\n",
    "    # Dropout(dis_ldrop, name=\"EnDrop_2\"),\n",
    "\n",
    "    # intermediate convolutional encoder layer\n",
    "    Conv2D(int(filters/4), ksize, strides=stsize, activation=hid_ly_actf, padding=pad, name=\"EnConv_3\"),\n",
    "    MaxPooling2D(psize, padding=pad, name=\"EnPool_3\"),\n",
    "    Dropout(dis_ldrop, name=\"EnDrop_3\"),\n",
    "\n",
    "    # # intermediate convolutional encoder layer\n",
    "    # Conv2D(int(filters/8), ksize, strides=stsize, activation=act, padding=pad, name=\"EnConv_4\"),\n",
    "    # MaxPooling2D(psize, padding=pad, name=\"EnPool_4\"),\n",
    "    # Dropout(dis_ldrop, name=\"EnDrop_4\"),\n",
    "\n",
    "    # #from 2D to 1D\n",
    "    Flatten(name=\"LayFlat\"),\n",
    "\n",
    "    # mid dense encoding layer\n",
    "    Dense(dis_midn, activation=hid_ly_actf, name=\"MidDense\"),\n",
    "    Dropout(dis_ldrop, name=\"ClsDrop_1\"),\n",
    "\n",
    "    # intermediate dense classification layer\n",
    "    Dense(int(dis_midn/2), activation=hid_ly_actf, name=\"ClsDense_1\"),\n",
    "    # Dropout(dis_ldrop, name=\"ClsDrop_2\"),\n",
    "\n",
    "    # intermediate dense classification layer\n",
    "    Dense(int(dis_midn/4), activation=hid_ly_actf, name=\"ClsDense_2\"),\n",
    "    Dropout(dis_ldrop, name=\"ClsDrop_3\"),\n",
    "\n",
    "    # output layer, dense time sequential layer.\n",
    "    Dense(out_dis, activation=out_dis_act, name=\"LayClsOut\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_model = Sequential(dis_layers)\n",
    "dis_model.model_name = dis_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "dis_model.compile(loss=ls, optimizer=dis_opti, metrics=met)\n",
    "dis_model.trainable = False\n",
    "dis_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN layers\n",
    "gan_layers = (\n",
    "    gen_model, \n",
    "    dis_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model = Sequential(gan_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model.compile(loss=ls, optimizer=gan_opti, metrics=met)\n",
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model topology into png files\n",
    "export_model(gen_model, model_fn_path, gen_model_name, timestamp)\n",
    "export_model(dis_model, model_fn_path, dis_model_name, timestamp)\n",
    "export_model(gan_model, model_fn_path, gan_model_name, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config for training\n",
    "fn_config = (model_fn_path, report_fn_path, dis_model_name, gen_model_name, gan_model_name)\n",
    "check_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing according to train/test proportions\n",
    "# Xt_train, Xt_test, Xi_train, Xi_test = train_test_split(X_txt, X_img, train_size = train_split, test_size = test_split, random_state = randseed)\n",
    "# Xi_train, Xi_test, y_train, y_test = train_test_split(X_img, y, train_size = train_split, test_size = test_split, random_state = randseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "train(gen_model, dis_model, gan_model, X_img, X_txt, y, epo, bs, check_epochs, fn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}